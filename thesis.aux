\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@input{glossary.aux}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\babel@aux{ngerman}{}
\babel@aux{ngerman}{}
\babel@aux{british}{}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Abstract}{v}{chapter*.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{mikolov2013efficient}
\citation{mikolov2013distributed}
\citation{pennington2014glove}
\citation{bojanowski2016enriching}
\citation{mikolov2013exploiting}
\citation{xing2015normalized}
\citation{artetxe2017learning}
\citation{cao2016distribution}
\citation{zhang2017adversarial}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Related Work}{2}{section.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Word Embedding}{2}{subsection.1.1.1}}
\citation{cohn2007machine}
\citation{cheng2016semi}
\citation{ravi2011deciphering}
\citation{nuhn2012deciphering}
\citation{nuhn2014decipherment}
\citation{kim2017unsupervised}
\citation{duong2016learning}
\citation{he2016dual}
\citation{artetxe2017unsupervised}
\citation{lample2017unsupervised}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Unsupervised Machine Translation}{3}{subsection.1.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Outline}{4}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Notation}{4}{section.1.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Machine Translation}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Statistical Machine Translation}{7}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Word-Based Model}{7}{subsection.2.1.1}}
\citation{koehn2009statistical}
\citation{koehn2009statistical}
\citation{koehn2009statistical}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline IBM Models}{8}{section*.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces  Illustration of a translation process using IBM-3 model (\cite  {koehn2009statistical})}}{9}{figure.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weighted Model}{9}{section*.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Phrase-Based Model}{9}{subsection.2.1.2}}
\citation{ravi2011deciphering}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Decipherment}{10}{subsection.2.1.3}}
\citation{sutskever2014sequence}
\citation{bahdanau2014neural}
\citation{luong2015effective}
\citation{gehring2017convolutional}
\citation{vaswani2017attention}
\citation{luong2015effective}
\citation{luong2015effective}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural Machine Translation}{11}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.2}{\ignorespaces  English$\rightarrow $ French translation\IeC {\textendash } example of a deep NMT (\cite  {luong2015effective}).}}{12}{figure.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Encoder-Decoder Framework}{12}{subsection.2.2.1}}
\citation{bahdanau2014neural}
\citation{luong2015effective}
\citation{luong2015effective}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Attention Mechanism}{13}{subsection.2.2.2}}
\citation{gehring2017convolutional}
\citation{vaswani2017attention}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.3}{\ignorespaces Global attention (\cite  {luong2015effective})}}{14}{figure.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Transformer}{14}{subsection.2.2.3}}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.4}{\ignorespaces The Transformer model architecture (\cite  {vaswani2017attention})}}{15}{figure.2.4}}
\citation{he2016dual}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.5}{\ignorespaces Self-attention structure}}{16}{figure.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Unsupervised Neural Machine Translation}{16}{subsection.2.2.4}}
\citation{he2016dual}
\citation{lample2018phrase}
\citation{lample2018phrase}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Unsupervised Machine Translation}}{17}{algorithm.1}}
\citation{neishi2017bag}
\citation{qi2018and}
\citation{lample2017unsupervised}
\citation{xing2015normalized}
\citation{lample2018phrase}
\citation{mikolov2013efficient}
\citation{pennington2014glove}
\citation{mikolov2013efficient}
\citation{mikolov2013efficient}
\citation{qi2018and}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Word Embedding}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Monolingual Embedding}{19}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}CBOW and Skip-gram}{19}{subsection.3.1.1}}
\citation{mikolov2013exploiting}
\citation{adams2017cross}
\citation{ruder2017survey}
\citation{ruder2017survey}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.1}{\ignorespaces Global attention model (\cite  {mikolov2013efficient})}}{20}{figure.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}GloVe}{20}{subsection.3.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.2}{\ignorespaces A cross-lingual embedding space between German and English (\cite  {ruder2017survey})}}{21}{figure.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Cross-lingual Word Embedding}{21}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Supervised Training}{21}{subsection.3.2.1}}
\citation{coulmance2016trans}
\citation{luong2015bilingual}
\citation{gouws2015bilbowa}
\citation{gouws2015bilbowa}
\citation{faruqui2014improving}
\citation{dhillon2011multi}
\citation{lu2015deep}
\citation{faruqui2014improving}
\citation{faruqui2014improving}
\citation{lu2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.3}{\ignorespaces Cross-lingual projection with CCA (\cite  {faruqui2014improving})}}{23}{figure.3.3}}
\citation{mikolov2013exploiting}
\citation{xing2015normalized}
\citation{smith2017offline}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Biligual Lexicon Induction}{24}{subsection.3.2.2}}
\citation{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Unsupervised Learning of Cross-lingual Word Embedding}{27}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Initialization}{27}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Heuristics}{27}{subsection.4.1.1}}
\citation{zhang2017adversarial}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Adversarial Training (GANs)}{28}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Similarity Matrix}{28}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Vocabulary-based Training}{28}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Iterative Procrustes Analysis}{28}{subsection.4.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Iterative training procedure}}{29}{algorithm.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Seed Dictionary Induction}{29}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Corpus-based Training}{29}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Motivation}{29}{subsection.4.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Iterative learning of corpus-based approach}}{30}{algorithm.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Online Training}{30}{subsection.4.3.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Online learning for corpus-based approach}}{30}{algorithm.4}}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Training Details}{31}{subsection.4.3.3}}
\citation{conneau2017word}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Sentence Translation}{35}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Context-aware Beam Search}{35}{section.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Language Model}{35}{subsection.5.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Beam Search}{36}{subsection.5.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Denoising Neural Network}{36}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Denoising Auto-encoder}{36}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Noise Model}{37}{subsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.1}{\ignorespaces  Reordering noise}}{37}{figure.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.2}{\ignorespaces Insertion noise}}{38}{figure.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.3}{\ignorespaces  Deletion noise}}{39}{figure.5.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Experiments}{41}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Corpus Statistics}{41}{section.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Word Translation}{42}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Baseline}{42}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Corpus Size for Monolingual Embedding}{42}{section*.6}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Vocabulary Size for Word Translation}{42}{section*.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Data-driven Approach}{42}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Different Learning Rate Scheduler}{42}{section*.8}}
\citation{lample2017unsupervised}
\citation{artetxe2017unsupervised}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Sentence Translation}{44}{section.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Comprehensive Table}{44}{subsection.6.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 6.1}{\ignorespaces Word-by-word translation from German to English}}{44}{table.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}BPE vs Word}{44}{subsection.6.3.2}}
\citation{mikolov2013distributed}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Artificial Noise}{45}{subsection.6.3.3}}
\newlabel{tab:denoising}{{6.3.3}{45}{Artificial Noise}{subsection.6.3.3}{}}
\newlabel{tab:denoising@cref}{{[subsection][3][6,3]6.3.3}{[1][44][]45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Phrase Embedding}{45}{subsection.6.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.5}Vocabulary Cutoff in Translation}{46}{subsection.6.3.5}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 6.2}{\ignorespaces Word embedding vocabulary cut-off}}{46}{table.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 6.3}{\ignorespaces Phrase embedding vocabulary cut-off}}{46}{table.6.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{47}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{49}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{koehn2009statistical}
\citation{luong2015effective}
\citation{luong2015effective}
\citation{vaswani2017attention}
\citation{mikolov2013efficient}
\citation{ruder2017survey}
\citation{faruqui2014improving}
\@writefile{toc}{\contentsline {chapter}{\nonumberline List of Figures}{51}{chapter*.9}}
\bibstyle{plainnat}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\nonumberline List of Tables}{53}{chapter*.10}}
\bibcite{adams2017cross}{{1}{2017}{{Adams et~al.}}{{Adams, Makarucha, Neubig, Bird, and Cohn}}}
\bibcite{artetxe2017learning}{{2}{2017{a}}{{Artetxe et~al.}}{{Artetxe, Labaka, and Agirre}}}
\bibcite{artetxe2017unsupervised}{{3}{2017{b}}{{Artetxe et~al.}}{{Artetxe, Labaka, Agirre, and Cho}}}
\bibcite{bahdanau2014neural}{{4}{2014}{{Bahdanau et~al.}}{{Bahdanau, Cho, and Bengio}}}
\bibcite{bojanowski2016enriching}{{5}{2016}{{Bojanowski et~al.}}{{Bojanowski, Grave, Joulin, and Mikolov}}}
\bibcite{cao2016distribution}{{6}{2016}{{Cao et~al.}}{{Cao, Zhao, Zhang, and Meng}}}
\bibcite{cheng2016semi}{{7}{2016}{{Cheng et~al.}}{{Cheng, Xu, He, He, Wu, Sun, and Liu}}}
\bibcite{cohn2007machine}{{8}{2007}{{Cohn and Lapata}}{{}}}
\bibcite{conneau2017word}{{9}{2017}{{Conneau et~al.}}{{Conneau, Lample, Ranzato, Denoyer, and J{\'e}gou}}}
\bibcite{coulmance2016trans}{{10}{2016}{{Coulmance et~al.}}{{Coulmance, Marty, Wenzek, and Benhalloum}}}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliography}{55}{chapter*.11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{dhillon2011multi}{{11}{2011}{{Dhillon et~al.}}{{Dhillon, Foster, and Ungar}}}
\bibcite{duong2016learning}{{12}{2016}{{Duong et~al.}}{{Duong, Kanayama, Ma, Bird, and Cohn}}}
\bibcite{faruqui2014improving}{{13}{2014}{{Faruqui and Dyer}}{{}}}
\bibcite{gehring2017convolutional}{{14}{2017}{{Gehring et~al.}}{{Gehring, Auli, Grangier, Yarats, and Dauphin}}}
\bibcite{gouws2015bilbowa}{{15}{2015}{{Gouws et~al.}}{{Gouws, Bengio, and Corrado}}}
\bibcite{he2016dual}{{16}{2016}{{He et~al.}}{{He, Xia, Qin, Wang, Yu, Liu, and Ma}}}
\bibcite{kim2017unsupervised}{{17}{2017}{{Kim et~al.}}{{Kim, Schamper, and Ney}}}
\bibcite{koehn2009statistical}{{18}{2009}{{Koehn}}{{}}}
\bibcite{lample2017unsupervised}{{19}{2017}{{Lample et~al.}}{{Lample, Denoyer, and Ranzato}}}
\bibcite{lample2018phrase}{{20}{2018}{{Lample et~al.}}{{Lample, Ott, Conneau, Denoyer, and Ranzato}}}
\bibcite{lu2015deep}{{21}{2015}{{Lu et~al.}}{{Lu, Wang, Bansal, Gimpel, and Livescu}}}
\bibcite{luong2015effective}{{22}{2015{a}}{{Luong et~al.}}{{Luong, Pham, and Manning}}}
\bibcite{luong2015bilingual}{{23}{2015{b}}{{Luong et~al.}}{{Luong, Pham, and Manning}}}
\bibcite{mikolov2013efficient}{{24}{2013{a}}{{Mikolov et~al.}}{{Mikolov, Chen, Corrado, and Dean}}}
\bibcite{mikolov2013exploiting}{{25}{2013{b}}{{Mikolov et~al.}}{{Mikolov, Le, and Sutskever}}}
\bibcite{mikolov2013distributed}{{26}{2013{c}}{{Mikolov et~al.}}{{Mikolov, Sutskever, Chen, Corrado, and Dean}}}
\bibcite{neishi2017bag}{{27}{2017}{{Neishi et~al.}}{{Neishi, Sakuma, Tohda, Ishiwatari, Yoshinaga, and Toyoda}}}
\bibcite{nuhn2014decipherment}{{28}{2014}{{Nuhn and Ney}}{{}}}
\bibcite{nuhn2012deciphering}{{29}{2012}{{Nuhn et~al.}}{{Nuhn, Mauser, and Ney}}}
\bibcite{pennington2014glove}{{30}{2014}{{Pennington et~al.}}{{Pennington, Socher, and Manning}}}
\bibcite{qi2018and}{{31}{2018}{{Qi et~al.}}{{Qi, Sachan, Felix, Padmanabhan, and Neubig}}}
\bibcite{ravi2011deciphering}{{32}{2011}{{Ravi and Knight}}{{}}}
\bibcite{ruder2017survey}{{33}{2017}{{Ruder et~al.}}{{Ruder, Vuli{\'c}, and S{\o }gaard}}}
\bibcite{smith2017offline}{{34}{2017}{{Smith et~al.}}{{Smith, Turban, Hamblin, and Hammerla}}}
\bibcite{sutskever2014sequence}{{35}{2014}{{Sutskever et~al.}}{{Sutskever, Vinyals, and Le}}}
\bibcite{vaswani2017attention}{{36}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{xing2015normalized}{{37}{2015}{{Xing et~al.}}{{Xing, Wang, Liu, and Lin}}}
\bibcite{zhang2017adversarial}{{38}{2017}{{Zhang et~al.}}{{Zhang, Liu, Luan, and Sun}}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{12.84798pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{18.37163pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{26.8883pt}
