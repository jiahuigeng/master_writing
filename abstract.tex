\chapter{Abstract}

The unsupervised learning of cross-lingual word embedding offers elegant word matches between languages, but there are fundamental limitations in sentence translation. In this work, we propose a simple yet effective method to improve the word-by-word sentence translation based on cross-lingual word embedding, using only monolingual corpora but without any back-translation. We integrate a language model for context-aware beam search, we also combine with a novel denoising autoencoder to handle reordering. Our system surpasses state-of-the-art unsupervised machine translation system without costly iterative training.  We also analyze the effects of parameters and artificial designed features in our model. We also propose a novel data-driven unsupervised learning of cross-lingual word embedding, which can be  actually describe as an iterative process combing the translation process and SGD training of word embedding. Since the quality of cross-lingual word embedding effects the performance of our model. Our contributions to embedding learning and translation system can provide better understanding of learning the cross-lingual word embedding and its usage in translation.