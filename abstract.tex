\chapter{Abstract}
Cross-lingual representations of words enable us to explore the distribution properties of different languages in a shared space. Based on semantic similarities reflected by cross-lingual word embeddings, we can implement bilingual dictionary induction, information retrieval and knowledge transfer between resource-rich and resource-lean languages.\\
%In this thesis we first make a survey of the cross-lingual word embedding training methods and its application in unsupervised machine translation. Then we proposed a novel training method of cross-lingual word embedding, which is data-driven and supported with language model, we can better utilize the context information for training. we further exploit the cross-lingual similarity in word-by-word based unsupervised machine translation combined with context-aware beam search and denoising autoencoder. \\
%The performance of the cross-lingual embedding is measuared on an open dictionary from Facebook, we find the performance is comparable with the state-of-the-art supervised and unsupervised methods. Based on that, our simple yet efficient unsupervised machine translation system can produce meaningful machine translation the BLEU scores even get beyond some unsupervised system with costly iterative training. \\
%We also make some ablation studies, analyze the effects of various factors in the cross-lingual word embedding training and various artificial noise. We think our work can provide better understanding of the training and the applications of word embedding in machine translation (MT).
In this thesis, I propose a novel training method of cross-lingual word embedding, which is distinct from other methods by  its corpus-based instead of vocabulary-based training process. It integrates embedding mapping learning, lexicon induction and corpus translation. 
Language model is exploited make better use of contextual information to improve the corpus translation.  The improvement of lexicon aids correspondingly cross-lingual word embedding. The performance of novel corpus-based approach is measured on a word retrieval. The experiments show that our method can achieve competitive results compared with the current supervised and unsupervised learning methods. \\
We further improve the unsupervised translation system with denoising neural network to handle reordering. The simple yet efficient translation system surpasses state-of-the-art unsupervised translation system without costly iteratively training.\\
We verify the cross-lingual embedding on subword units performs poorly in translation and show that vocabulary cut-off helps for sentence translation. We also analyze the effect of different artificial noises to denoising model and propose a novel noise type.


