\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adams et~al.(2017)Adams, Makarucha, Neubig, Bird, and
  Cohn]{adams2017cross}
Oliver Adams, Adam Makarucha, Graham Neubig, Steven Bird, and Trevor Cohn.
\newblock Cross-lingual word embeddings for low-resource language modeling.
\newblock In \emph{Proceedings of the 15th Conference of the European Chapter
  of the Association for Computational Linguistics: Volume 1, Long Papers},
  volume~1, pages 937--947, 2017.

\bibitem[Artetxe et~al.(2017{\natexlab{a}})Artetxe, Labaka, and
  Agirre]{artetxe2017learning}
Mikel Artetxe, Gorka Labaka, and Eneko Agirre.
\newblock Learning bilingual word embeddings with (almost) no bilingual data.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  451--462, 2017{\natexlab{a}}.

\bibitem[Artetxe et~al.(2017{\natexlab{b}})Artetxe, Labaka, Agirre, and
  Cho]{artetxe2017unsupervised}
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho.
\newblock Unsupervised neural machine translation.
\newblock \emph{arXiv preprint arXiv:1710.11041}, 2017{\natexlab{b}}.

\bibitem[Bojanowski et~al.(2016)Bojanowski, Grave, Joulin, and
  Mikolov]{bojanowski2016enriching}
Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.
\newblock Enriching word vectors with subword information.
\newblock \emph{arXiv preprint arXiv:1607.04606}, 2016.

\bibitem[Cao et~al.(2016)Cao, Zhao, Zhang, and Meng]{cao2016distribution}
Hailong Cao, Tiejun Zhao, Shu Zhang, and Yao Meng.
\newblock A distribution-based model to learn bilingual word embeddings.
\newblock In \emph{Proceedings of COLING 2016, the 26th International
  Conference on Computational Linguistics: Technical Papers}, pages 1818--1827,
  2016.

\bibitem[Cheng et~al.(2016)Cheng, Xu, He, He, Wu, Sun, and Liu]{cheng2016semi}
Yong Cheng, Wei Xu, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu.
\newblock Semi-supervised learning for neural machine translation.
\newblock \emph{arXiv preprint arXiv:1606.04596}, 2016.

\bibitem[Cohn and Lapata(2007)]{cohn2007machine}
Trevor Cohn and Mirella Lapata.
\newblock Machine translation by triangulation: Making effective use of
  multi-parallel corpora.
\newblock In \emph{Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, pages 728--735, 2007.

\bibitem[Conneau et~al.(2017)Conneau, Lample, Ranzato, Denoyer, and
  J{\'e}gou]{conneau2017word}
Alexis Conneau, Guillaume Lample, Marc'Aurelio Ranzato, Ludovic Denoyer, and
  Herv{\'e} J{\'e}gou.
\newblock Word translation without parallel data.
\newblock \emph{arXiv preprint arXiv:1710.04087}, 2017.

\bibitem[Duong et~al.(2016)Duong, Kanayama, Ma, Bird, and
  Cohn]{duong2016learning}
Long Duong, Hiroshi Kanayama, Tengfei Ma, Steven Bird, and Trevor Cohn.
\newblock Learning crosslingual word embeddings without bilingual corpora.
\newblock \emph{arXiv preprint arXiv:1606.09403}, 2016.

\bibitem[Gehring et~al.(2017)Gehring, Auli, Grangier, Yarats, and
  Dauphin]{gehring2017convolutional}
Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann~N Dauphin.
\newblock Convolutional sequence to sequence learning.
\newblock \emph{arXiv preprint arXiv:1705.03122}, 2017.

\bibitem[He et~al.(2016)He, Xia, Qin, Wang, Yu, Liu, and Ma]{he2016dual}
Di~He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tieyan Liu, and Wei-Ying
  Ma.
\newblock Dual learning for machine translation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  820--828, 2016.

\bibitem[Hoshen and Wolf(2018)]{DBLP:journals/corr/abs-1801-06126}
Yedid Hoshen and Lior Wolf.
\newblock An iterative closest point method for unsupervised word translation.
\newblock \emph{CoRR}, abs/1801.06126, 2018.
\newblock URL \url{http://arxiv.org/abs/1801.06126}.

\bibitem[Kim et~al.(2017)Kim, Schamper, and Ney]{kim2017unsupervised}
Yunsu Kim, Julian Schamper, and Hermann Ney.
\newblock Unsupervised training for large vocabulary translation using sparse
  lexicon and word classes.
\newblock In \emph{Proceedings of the 15th Conference of the European Chapter
  of the Association for Computational Linguistics: Volume 2, Short Papers},
  volume~2, pages 650--656, 2017.

\bibitem[Lample et~al.(2017)Lample, Denoyer, and
  Ranzato]{lample2017unsupervised}
Guillaume Lample, Ludovic Denoyer, and Marc'Aurelio Ranzato.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock \emph{arXiv preprint arXiv:1711.00043}, 2017.

\bibitem[Lample et~al.(2018)Lample, Ott, Conneau, Denoyer, and
  Ranzato]{lample2018phrase}
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio
  Ranzato.
\newblock Phrase-based \& neural unsupervised machine translation.
\newblock \emph{arXiv preprint arXiv:1804.07755}, 2018.

\bibitem[Luong et~al.(2015)Luong, Pham, and Manning]{luong2015effective}
Minh-Thang Luong, Hieu Pham, and Christopher~D Manning.
\newblock Effective approaches to attention-based neural machine translation.
\newblock \emph{arXiv preprint arXiv:1508.04025}, 2015.

\bibitem[Mikolov et~al.(2013{\natexlab{a}})Mikolov, Chen, Corrado, and
  Dean]{mikolov2013efficient}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock \emph{arXiv preprint arXiv:1301.3781}, 2013{\natexlab{a}}.

\bibitem[Mikolov et~al.(2013{\natexlab{b}})Mikolov, Le, and
  Sutskever]{mikolov2013exploiting}
Tomas Mikolov, Quoc~V Le, and Ilya Sutskever.
\newblock Exploiting similarities among languages for machine translation.
\newblock \emph{arXiv preprint arXiv:1309.4168}, 2013{\natexlab{b}}.

\bibitem[Mikolov et~al.(2013{\natexlab{c}})Mikolov, Sutskever, Chen, Corrado,
  and Dean]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pages
  3111--3119, 2013{\natexlab{c}}.

\bibitem[Nuhn and Ney(2014)]{nuhn2014decipherment}
Malte Nuhn and Hermann Ney.
\newblock Em decipherment for large vocabularies.
\newblock In \emph{Proceedings of the 52nd Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, volume~2, pages
  759--764, 2014.

\bibitem[Nuhn et~al.(2012)Nuhn, Mauser, and Ney]{nuhn2012deciphering}
Malte Nuhn, Arne Mauser, and Hermann Ney.
\newblock Deciphering foreign language by combining language models and context
  vectors.
\newblock In \emph{Proceedings of the 50th Annual Meeting of the Association
  for Computational Linguistics: Long Papers-Volume 1}, pages 156--164.
  Association for Computational Linguistics, 2012.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher Manning.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem[Ravi and Knight(2011)]{ravi2011deciphering}
Sujith Ravi and Kevin Knight.
\newblock Deciphering foreign language.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies-Volume 1}, pages
  12--21. Association for Computational Linguistics, 2011.

\bibitem[Ruder et~al.(2017)Ruder, Vuli{\'c}, and S{\o}gaard]{ruder2017survey}
Sebastian Ruder, Ivan Vuli{\'c}, and Anders S{\o}gaard.
\newblock A survey of cross-lingual word embedding models.
\newblock \emph{arXiv preprint arXiv:1706.04902}, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5998--6008, 2017.

\bibitem[Vulic and Korhonen(2016)]{vulic2016role}
Ivan Vulic and Anna-Leena Korhonen.
\newblock On the role of seed lexicons in learning bilingual word embeddings.
\newblock 2016.

\bibitem[Xing et~al.(2015)Xing, Wang, Liu, and Lin]{xing2015normalized}
Chao Xing, Dong Wang, Chao Liu, and Yiye Lin.
\newblock Normalized word embedding and orthogonal transform for bilingual word
  translation.
\newblock In \emph{Proceedings of the 2015 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1006--1011, 2015.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhudinov, Zemel, and
  Bengio]{xu2015show}
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan
  Salakhudinov, Rich Zemel, and Yoshua Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In \emph{International conference on machine learning}, pages
  2048--2057, 2015.

\bibitem[Zhang et~al.(2017)Zhang, Liu, Luan, and Sun]{zhang2017adversarial}
Meng Zhang, Yang Liu, Huanbo Luan, and Maosong Sun.
\newblock Adversarial training for unsupervised bilingual lexicon induction.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  1959--1970, 2017.

\end{thebibliography}
