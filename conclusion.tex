\chapter{Conclusion}
%
%
%For unsupervised machine translation system, the context-aware beam search language model help at the lexicon choice step.\\
%The denoising networks which aimed at the insertion/deletion/reordering noise in the word-by-word translation sentence works well for fertility and localized reordering problem. 
%Even though BPE is known to be an effective way to overcome the rare word problem in standard NMT, BPE embedding performs worse than word embedding in our case especially when vocabulary is small.\\
%Word-by-word translation based on cross-lingual word embedding depends highly on the frequent word mappings. We found that phrase embedding only helps in word-by-word translation with context-aware beam search, it works not as good as that under the processing of denoising autoencoder.

The main contributions of this thesis are 1) a novel corpus-based training approach for cross-lingual word embeddings, 2) integration of LM and DAE to improve the unsupervised translation performance. \\
The corpus-based approach combines the cross-lingual embedding learning, a word-by-word -- a simplified word based machine translation. The improvements of sub-models will feed each other to make the entire system improved. \\
As to unsupervised MT, we achieved context-aware lexical choices using beam search and solved insertion/deletion/reordering problems using artificial noises. Actually insertion noise is a new noise type that first implemented in sequential denosing tasks and we observe up to $1.5$ BLEU score improvement with that noise for translation from German to English.  Our approach does no need expensive back-translation but still surpasses state-of-the-art unsupervised NMT systems.