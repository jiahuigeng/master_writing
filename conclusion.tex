\chapter{Conclusion}
%
%
%For unsupervised machine translation system, the context-aware beam search language model help at the lexicon choice step.\\
%The denoising networks which aimed at the insertion/deletion/reordering noise in the word-by-word translation sentence works well for fertility and localized reordering problem. 
%Even though BPE is known to be an effective way to overcome the rare word problem in standard NMT, BPE embedding performs worse than word embedding in our case especially when vocabulary is small.\\
%Word-by-word translation based on cross-lingual word embedding depends highly on the frequent word mappings. We found that phrase embedding only helps in word-by-word translation with context-aware beam search, it works not as good as that under the processing of denoising autoencoder.

The main contributions of this thesis are 1) a novel corpus-based training approach for cross-lingual word embeddings, 2) integration of LM and DAE to improve the unsupervised translation performance. \\
The corpus-based approach integrates corpus translation, lexicon induction into the mapping learning process. The performance measured on a cross-lingual word retrieval task shows that our approach can achieve competitive results, better than adversarial training only. In the future work, we can joint train the mapping with target $\rightarrow$ source translation, dictionary thresholding and replace word-by-word translation by more complex model with alignment model for reordering. We expect final results will get further improved.\\
We implement context-aware lexical choice using beam search and solved insertion/deletion/reordering problems by modeling artificial noises in DAE. Actually insertion noise is a first introduced in sequential denosing tasks and leads to $1.5$ BLEU score for WMT \texttt{newstest2016}  German $\rightarrow$ English.  Our approach does not need expensive back-translation but still surpasses state-of-the-art unsupervised NMT systems.\\
As ablation studies, we examine the effect of training corpus, each noise type in DAE, how the translation performance varies with different vocabulary size, and the effects of BPE.




